{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    l = []\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.label()=='NP'):\n",
    "        l.append(subtree.leaves())\n",
    "    \n",
    "    return l\n",
    "\n",
    "def normalise(word):\n",
    "    \"\"\"Normalises words to lowercase and stems and lemmatizes it.\"\"\"\n",
    "    word = word.lower()\n",
    "    #word = stemmer.stem(word)\n",
    "    #word = lemmatizer.lemmatize(word)\n",
    "    return word\n",
    "\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    accepted = bool(2 <= len(word) <= 40\n",
    "        and word.lower() not in stopwords)\n",
    "    return accepted\n",
    "\n",
    "\n",
    "def get_terms(tree):\n",
    "    kp = []\n",
    "    for leaf in leaves(tree):\n",
    "        term = [ normalise(w) for w,t in leaf if acceptable_word(w) ]\n",
    "        if term:\n",
    "            kp.append(term)\n",
    "    \n",
    "    return kp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_kp(text):\n",
    "    \n",
    "    # Used when tokenizing words\n",
    "    sentence_re = r'''(?x)      # set flag to allow verbose regexps\n",
    "            (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "          | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "          | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "          | \\.\\.\\.              # ellipsis\n",
    "          | [][.,;\"'?():_`-#]    # these are separate tokens; includes ], [\n",
    "        '''\n",
    "\n",
    "    #lemmatizer = nltk.WordNetLemmatizer()\n",
    "    #stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    #Taken from Su Nam Kim Paper\n",
    "    grammar = r\"\"\"\n",
    "        NBAR:\n",
    "            {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n",
    "            {<JJ|JJR|JJS|VBG|VBN>*<NN|NNS|NNP|NNPS|VBG>}\n",
    "        NP:\n",
    "            {<NBAR>}\n",
    "            {<NBAR><IN><NBAR>}  # Above, connected with in/of/etc...\n",
    "    \"\"\"\n",
    "\n",
    "    #toks = nltk.regexp_tokenize(text, sentence_re)\n",
    "    postoks = nltk.tag.pos_tag(text)\n",
    "    chunker = nltk.RegexpParser(grammar)\n",
    "    tree = chunker.parse(postoks)\n",
    "    terms = get_terms(tree)\n",
    "    #pos,pos_set = find_positions(text,terms)\n",
    "    return terms#,pos,pos_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Inspec/docsutf8/'\n",
    "keys = 'Inspec/keys/'\n",
    "files = os.listdir(data)\n",
    "key_files = os.listdir(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positions(document,bert_tocs, kps):\n",
    "    ''' \n",
    "    merge the same kps & keep present kps in document\n",
    "    Inputs:\n",
    "        document : a word list : ['sun', 'sunshine', ...] || lower cased\n",
    "        kps : can have more than one kp : [['sun'], ['key','phrase'], ['sunshine']] || not duplicate\n",
    "    Outputs:\n",
    "        all_present_kps : present keyphrases\n",
    "        positions_for_all : start_end_posisiton for prensent keyphrases\n",
    "        a present kp postions list : every present's positions in documents, \n",
    "        each kp can be presented in several postions .\n",
    "        [[[0,0],[20,21]], [[1,1]]]\n",
    "    '''\n",
    "    tot_doc_char = ' '.join(document)\n",
    "    \n",
    "    positions_for_all = []\n",
    "    position_start,position_end =[],[]\n",
    "    all_present_kps = []\n",
    "    for kp in kps:\n",
    "        ans_string = ' '.join(kp)\n",
    "        \n",
    "        if ans_string not in tot_doc_char:\n",
    "            continue\n",
    "        else: \n",
    "            positions_for_each = []\n",
    "            # find all positions for each kp\n",
    "            for i in range(0, len(bert_tocs) - len(kp) + 1):\n",
    "                found = False\n",
    "                search_str = ''\n",
    "                if ans_string.startswith(bert_tocs[i]):\n",
    "                    found = True\n",
    "                    search_str +=bert_tocs[i]\n",
    "                    search_idx = i\n",
    "                    while found and search_idx<(len(bert_tocs)-1):\n",
    "                        search_idx+=1\n",
    "                        if search_str+bert_tocs[search_idx] in ans_string:\n",
    "                            search_str+=bert_tocs[search_idx]\n",
    "                        elif search_str+' '+bert_tocs[search_idx] in ans_string:\n",
    "                            search_str+=' '+bert_tocs[search_idx]\n",
    "                        else:\n",
    "                            found = False\n",
    "                        \n",
    "                if (search_str==ans_string) and (i<search_idx):\n",
    "                    assert len(kp) >= 1\n",
    "                    positions_for_each.append((i+1, search_idx))\n",
    "                    position_start.append(i+1)\n",
    "                    position_end.append(search_idx)\n",
    "                    \n",
    "        if len(positions_for_each) > 0 :\n",
    "            positions_for_all.extend(positions_for_each)\n",
    "            all_present_kps.append(kp)\n",
    "           \n",
    "    assert len(positions_for_all) >= len(all_present_kps)\n",
    "    \n",
    "    if len(all_present_kps) == 0:\n",
    "        return [None,None]\n",
    "    return [position_start,position_end],set(positions_for_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(y_labels,y_preds,depth,levels):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    for idx,y_label in enumerate(y_labels):\n",
    "        tp = 0\n",
    "        p = []\n",
    "        r = []\n",
    "        y_label = set(np.where(y_label==1)[0])\n",
    "        \n",
    "        #print(y_preds[idx].shape)\n",
    "        key_idx = np.argsort(-y_preds[idx])#[:,0])\n",
    "        #print(sorted(-y_preds[idx]))\n",
    "        y_new = np.sort(y_preds[idx])[::-1]\n",
    "        #print(y_preds[idx])\n",
    "        preds = key_idx[y_new>=0.5]\n",
    "        for i in range(depth):\n",
    "            if len(preds)>i:\n",
    "                if preds[i] in y_label:\n",
    "                    tp+=1\n",
    "            p.append(tp/(min(i,len(preds))+1))\n",
    "            r.append(tp/max(len(y_label),1))\n",
    "    \n",
    "    \n",
    "        level_index = []\n",
    "        level_p = []\n",
    "        level_r = []\n",
    "        for idx,level in enumerate(levels):\n",
    "            level_p.append(p[level-1])\n",
    "            level_r.append(r[level-1])\n",
    "            if p[level-1]+r[level-1]>0:\n",
    "                level_index.append(2*p[level-1]*r[level-1]/(p[level-1]+r[level-1]))\n",
    "            else:\n",
    "                level_index.append(0)\n",
    "        #print('k',level_index)\n",
    "        precision.append(level_p)\n",
    "        recall.append(level_r)\n",
    "        f1.append(level_index)\n",
    "    precision = np.array(precision)\n",
    "    recall = np.array(recall)\n",
    "    f1 = np.array(f1)\n",
    "    \n",
    "    print('F1',np.mean(f1,axis=0),np.mean(precision,axis=0),np.mean(recall,axis=0))\n",
    "    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "vocab = \"D:/Word embedding/bert/assets/vocab.txt\"\n",
    "tokenizer = BertWordPieceTokenizer(vocab, lowercase=True)\n",
    "encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15487, 2, 258)\n",
      "(15487, 258, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.convert_to_tensor(np.loadtxt('Data/KP20/x_train.csv'))\n",
    "x_mask = tf.convert_to_tensor(np.loadtxt('Data/KP20/x_mask_train.csv'))\n",
    "with open('Data/KP20/x_pos_train.pkl','rb') as f:\n",
    "    x_pos = tf.convert_to_tensor(pickle.load(f))\n",
    "    print(x_pos.shape)\n",
    "\n",
    "with open('Data/KP20/y_train.pkl','rb') as f:\n",
    "    y_train = tf.convert_to_tensor(pickle.load(f))\n",
    "    print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = x_train.shape[-1]\n",
    "max_kp = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "embedding = encoder(input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "bilstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(36,\n",
    "                                                             kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.00,stddev=0.15),\n",
    "                                                             dropout = 0.15,\n",
    "                                                             return_sequences=True),\n",
    "                                                             merge_mode=None)(embedding)\n",
    "pos_mask = tf.keras.layers.Input(shape=(2,max_kp),dtype='int32')\n",
    "mask_start = pos_mask[0][0]\n",
    "mask_end = pos_mask[0][1]\n",
    "\n",
    "start_rep_fr = tf.gather(bilstm1[0],mask_start,axis=1)\n",
    "start_rep_bk = tf.gather(bilstm1[1],mask_start,axis=1)\n",
    "end_rep_fr = tf.gather(bilstm1[0],mask_end,axis=1)\n",
    "end_rep_bk = tf.gather(bilstm1[0],mask_end,axis=1)\n",
    "\n",
    "\n",
    "span_fe_diff_fr = start_rep_fr-end_rep_fr\n",
    "span_fe_prod_fr = tf.math.multiply(start_rep_fr,end_rep_fr)\n",
    "span_fe_diff_bk = start_rep_bk-end_rep_bk\n",
    "span_fe_prod_bk = tf.math.multiply(start_rep_bk,end_rep_bk)\n",
    "\n",
    "\n",
    "span_fe = tf.keras.layers.concatenate([start_rep_fr,\n",
    "                     end_rep_fr,\n",
    "                     start_rep_bk,\n",
    "                     end_rep_bk,\n",
    "                     span_fe_diff_fr,\n",
    "                     span_fe_diff_bk,\n",
    "                     span_fe_prod_fr,\n",
    "                     span_fe_prod_bk\n",
    "                    ],2)\n",
    "\n",
    "bilstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(6,return_sequences=True,dropout = 0.25,\n",
    "                                                            #kernel_initializer=tf.keras.initializers.(mean=0.0,stddev=0.05),\n",
    "                                                            ),\n",
    "                                        \n",
    "                                         merge_mode='concat',\n",
    "                                         input_shape=(max_kp,30*4))(span_fe)\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(bilstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpe_model = tf.keras.models.Model(inputs=[input_ids,attention_mask,pos_mask], outputs=output)\n",
    "kpe_model.layers[3].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2, 258)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 512, 768), ( 109482240   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(2, 258)]           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(2, 258)]           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 512, 36), (N 231840      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(258,)]             0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(258,)]             0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2 (TensorFlo [(None, 258, 36)]    0           bidirectional[0][0]              \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_2 (TensorF [(None, 258, 36)]    0           bidirectional[0][0]              \n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_1 (TensorF [(None, 258, 36)]    0           bidirectional[0][1]              \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_3 (TensorF [(None, 258, 36)]    0           bidirectional[0][0]              \n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 258, 36)]    0           tf_op_layer_GatherV2[0][0]       \n",
      "                                                                 tf_op_layer_GatherV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 258, 36)]    0           tf_op_layer_GatherV2_1[0][0]     \n",
      "                                                                 tf_op_layer_GatherV2_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 258, 36)]    0           tf_op_layer_GatherV2[0][0]       \n",
      "                                                                 tf_op_layer_GatherV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 258, 36)]    0           tf_op_layer_GatherV2_1[0][0]     \n",
      "                                                                 tf_op_layer_GatherV2_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 258, 288)     0           tf_op_layer_GatherV2[0][0]       \n",
      "                                                                 tf_op_layer_GatherV2_2[0][0]     \n",
      "                                                                 tf_op_layer_GatherV2_1[0][0]     \n",
      "                                                                 tf_op_layer_GatherV2_3[0][0]     \n",
      "                                                                 tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Sub_1[0][0]          \n",
      "                                                                 tf_op_layer_Mul[0][0]            \n",
      "                                                                 tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 258, 12)      14160       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 258, 1)       13          bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 109,728,253\n",
      "Trainable params: 246,013\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(kpe_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.16838203>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(y_train[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    #print(y_pred.shape,y_true.shape)\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    y_true = tf.clip_by_value(y_true-1, 0, 1)\n",
    "    #loss_ = loss_object(y_true[mask], y_pred[mask])\n",
    "    pos = tf.math.logical_and(tf.math.equal(y_true, 1),mask)\n",
    "    loss_ = -tf.reduce_sum(20.0*tf.math.log(y_pred[pos]+0.01))-tf.reduce_sum(tf.math.log(0.99-y_pred[tf.logical_not(pos)]))\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "    #loss_ = tf.boolean_mask(loss_,mask)\n",
    "    \n",
    "    return loss_#tf.reduce_mean(tf.reduce_sum(loss_,axis=1)/tf.reduce_sum(mask,axis=1))\n",
    "\n",
    "\n",
    "def ac_metrics(y_true,y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    y_true = tf.cast(tf.clip_by_value(y_true-1, 0, 1),dtype='int32')\n",
    "    y_pred = tf.cast(tf.where(y_pred>=0.5,1,0),dtype='int32')\n",
    "    diff = tf.cast(tf.math.equal(y_true,y_pred),dtype='int32')\n",
    "    mask = tf.cast(mask, dtype=diff.dtype)\n",
    "    diff*= mask\n",
    "    \n",
    "    return tf.reduce_mean(tf.reduce_sum(diff,axis=1)/tf.reduce_sum(mask,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00009)\n",
    "kpe_model.compile(optimizer=opt,\n",
    "              loss=loss_function,\n",
    "              metrics=[ac_metrics])\n",
    "\n",
    "#checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_ac_metrics:.2f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_ac_metrics', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/383 [===========>..................] - ETA: 3s - loss: 4254.2114 - ac_metrics: 0.892 - ETA: 12:03 - loss: 3639.7097 - ac_metrics: 0.71 - ETA: 16:01 - loss: 3300.6658 - ac_metrics: 0.59 - ETA: 17:59 - loss: 3143.0601 - ac_metrics: 0.62 - ETA: 19:06 - loss: 3145.4731 - ac_metrics: 0.61 - ETA: 19:52 - loss: 3040.2185 - ac_metrics: 0.61 - ETA: 20:22 - loss: 3047.3337 - ac_metrics: 0.59 - ETA: 20:45 - loss: 3101.5347 - ac_metrics: 0.56 - ETA: 21:01 - loss: 3121.8105 - ac_metrics: 0.56 - ETA: 21:14 - loss: 3164.9258 - ac_metrics: 0.54 - ETA: 21:23 - loss: 3143.9009 - ac_metrics: 0.57 - ETA: 21:30 - loss: 3133.8403 - ac_metrics: 0.56 - ETA: 21:36 - loss: 3128.4995 - ac_metrics: 0.58 - ETA: 21:40 - loss: 3105.3926 - ac_metrics: 0.57 - ETA: 21:43 - loss: 3144.5977 - ac_metrics: 0.55 - ETA: 21:46 - loss: 3166.0168 - ac_metrics: 0.54 - ETA: 21:48 - loss: 3182.7170 - ac_metrics: 0.54 - ETA: 21:49 - loss: 3132.1121 - ac_metrics: 0.53 - ETA: 21:49 - loss: 3107.2310 - ac_metrics: 0.54 - ETA: 21:50 - loss: 3063.0796 - ac_metrics: 0.55 - ETA: 21:50 - loss: 3053.2913 - ac_metrics: 0.56 - ETA: 21:49 - loss: 3072.5837 - ac_metrics: 0.56 - ETA: 21:48 - loss: 3135.7993 - ac_metrics: 0.57 - ETA: 21:47 - loss: 3128.8979 - ac_metrics: 0.56 - ETA: 21:46 - loss: 3099.8777 - ac_metrics: 0.56 - ETA: 21:45 - loss: 3077.5198 - ac_metrics: 0.55 - ETA: 21:43 - loss: 3050.7798 - ac_metrics: 0.55 - ETA: 21:42 - loss: 3068.3645 - ac_metrics: 0.56 - ETA: 21:40 - loss: 3074.0134 - ac_metrics: 0.56 - ETA: 21:38 - loss: 3073.0654 - ac_metrics: 0.56 - ETA: 21:36 - loss: 3053.0623 - ac_metrics: 0.57 - ETA: 21:34 - loss: 3049.6511 - ac_metrics: 0.56 - ETA: 21:31 - loss: 3051.0359 - ac_metrics: 0.56 - ETA: 21:29 - loss: 3047.4268 - ac_metrics: 0.56 - ETA: 21:26 - loss: 3072.8098 - ac_metrics: 0.56 - ETA: 21:24 - loss: 3130.4475 - ac_metrics: 0.57 - ETA: 21:21 - loss: 3118.3672 - ac_metrics: 0.58 - ETA: 21:18 - loss: 3166.2080 - ac_metrics: 0.59 - ETA: 21:16 - loss: 3166.7827 - ac_metrics: 0.59 - ETA: 21:13 - loss: 3170.6768 - ac_metrics: 0.59 - ETA: 21:10 - loss: 3169.7542 - ac_metrics: 0.59 - ETA: 21:07 - loss: 3178.0132 - ac_metrics: 0.59 - ETA: 21:04 - loss: 3172.4412 - ac_metrics: 0.59 - ETA: 21:01 - loss: 3172.3682 - ac_metrics: 0.59 - ETA: 20:58 - loss: 3164.7710 - ac_metrics: 0.60 - ETA: 20:55 - loss: 3157.4424 - ac_metrics: 0.60 - ETA: 20:52 - loss: 3153.4531 - ac_metrics: 0.60 - ETA: 20:49 - loss: 3165.5295 - ac_metrics: 0.60 - ETA: 20:46 - loss: 3155.9258 - ac_metrics: 0.60 - ETA: 20:42 - loss: 3160.4734 - ac_metrics: 0.60 - ETA: 20:39 - loss: 3164.7896 - ac_metrics: 0.60 - ETA: 20:36 - loss: 3160.5549 - ac_metrics: 0.60 - ETA: 20:33 - loss: 3148.6045 - ac_metrics: 0.60 - ETA: 20:30 - loss: 3130.2031 - ac_metrics: 0.60 - ETA: 20:26 - loss: 3114.8354 - ac_metrics: 0.60 - ETA: 20:23 - loss: 3107.3735 - ac_metrics: 0.60 - ETA: 20:20 - loss: 3101.8574 - ac_metrics: 0.60 - ETA: 20:16 - loss: 3103.9028 - ac_metrics: 0.61 - ETA: 20:13 - loss: 3106.6401 - ac_metrics: 0.61 - ETA: 20:10 - loss: 3117.2263 - ac_metrics: 0.61 - ETA: 20:06 - loss: 3118.6318 - ac_metrics: 0.61 - ETA: 20:03 - loss: 3123.0344 - ac_metrics: 0.61 - ETA: 20:00 - loss: 3124.5894 - ac_metrics: 0.61 - ETA: 19:56 - loss: 3115.0935 - ac_metrics: 0.61 - ETA: 19:53 - loss: 3128.5676 - ac_metrics: 0.61 - ETA: 19:49 - loss: 3126.7126 - ac_metrics: 0.61 - ETA: 19:46 - loss: 3127.8772 - ac_metrics: 0.60 - ETA: 19:42 - loss: 3131.7319 - ac_metrics: 0.60 - ETA: 19:39 - loss: 3140.5225 - ac_metrics: 0.60 - ETA: 19:35 - loss: 3136.4946 - ac_metrics: 0.60 - ETA: 19:32 - loss: 3145.8247 - ac_metrics: 0.60 - ETA: 19:28 - loss: 3157.0771 - ac_metrics: 0.61 - ETA: 19:25 - loss: 3150.5398 - ac_metrics: 0.61 - ETA: 19:21 - loss: 3152.0498 - ac_metrics: 0.61 - ETA: 19:18 - loss: 3149.2729 - ac_metrics: 0.61 - ETA: 19:14 - loss: 3143.9053 - ac_metrics: 0.61 - ETA: 19:11 - loss: 3150.7483 - ac_metrics: 0.61 - ETA: 19:07 - loss: 3155.6360 - ac_metrics: 0.61 - ETA: 19:04 - loss: 3179.6875 - ac_metrics: 0.61 - ETA: 19:00 - loss: 3178.2046 - ac_metrics: 0.61 - ETA: 18:56 - loss: 3175.1917 - ac_metrics: 0.61 - ETA: 18:53 - loss: 3182.3669 - ac_metrics: 0.61 - ETA: 18:49 - loss: 3188.8916 - ac_metrics: 0.61 - ETA: 18:46 - loss: 3178.9104 - ac_metrics: 0.61 - ETA: 18:42 - loss: 3189.5029 - ac_metrics: 0.61 - ETA: 18:38 - loss: 3180.3770 - ac_metrics: 0.61 - ETA: 18:35 - loss: 3175.6797 - ac_metrics: 0.61 - ETA: 18:31 - loss: 3178.8730 - ac_metrics: 0.61 - ETA: 18:28 - loss: 3184.0820 - ac_metrics: 0.61 - ETA: 18:24 - loss: 3177.6626 - ac_metrics: 0.61 - ETA: 18:20 - loss: 3171.3916 - ac_metrics: 0.61 - ETA: 18:17 - loss: 3178.9963 - ac_metrics: 0.61 - ETA: 18:13 - loss: 3174.1328 - ac_metrics: 0.61 - ETA: 18:10 - loss: 3177.8606 - ac_metrics: 0.61 - ETA: 18:06 - loss: 3178.6025 - ac_metrics: 0.62 - ETA: 18:02 - loss: 3180.9626 - ac_metrics: 0.62 - ETA: 17:59 - loss: 3177.5229 - ac_metrics: 0.62 - ETA: 17:55 - loss: 3175.5579 - ac_metrics: 0.61 - ETA: 17:51 - loss: 3178.5562 - ac_metrics: 0.62 - ETA: 17:48 - loss: 3174.9268 - ac_metrics: 0.62 - ETA: 17:44 - loss: 3183.8040 - ac_metrics: 0.61 - ETA: 17:40 - loss: 3179.1790 - ac_metrics: 0.61 - ETA: 17:37 - loss: 3176.3833 - ac_metrics: 0.61 - ETA: 17:33 - loss: 3181.7522 - ac_metrics: 0.61 - ETA: 17:29 - loss: 3178.1287 - ac_metrics: 0.61 - ETA: 17:26 - loss: 3175.7026 - ac_metrics: 0.61 - ETA: 17:22 - loss: 3184.1675 - ac_metrics: 0.61 - ETA: 17:18 - loss: 3178.6833 - ac_metrics: 0.61 - ETA: 17:15 - loss: 3180.1687 - ac_metrics: 0.61 - ETA: 17:11 - loss: 3182.9944 - ac_metrics: 0.61 - ETA: 17:07 - loss: 3181.5327 - ac_metrics: 0.61 - ETA: 17:04 - loss: 3187.3201 - ac_metrics: 0.61 - ETA: 17:00 - loss: 3188.3914 - ac_metrics: 0.61 - ETA: 16:56 - loss: 3182.9026 - ac_metrics: 0.61 - ETA: 16:53 - loss: 3177.8557 - ac_metrics: 0.61 - ETA: 16:49 - loss: 3175.8113 - ac_metrics: 0.61 - ETA: 16:45 - loss: 3171.0759 - ac_metrics: 0.61 - ETA: 16:42 - loss: 3167.4094 - ac_metrics: 0.61 - ETA: 16:38 - loss: 3165.5747 - ac_metrics: 0.61 - ETA: 16:34 - loss: 3160.2358 - ac_metrics: 0.61 - ETA: 16:30 - loss: 3161.3403 - ac_metrics: 0.61 - ETA: 16:27 - loss: 3162.1526 - ac_metrics: 0.61 - ETA: 16:23 - loss: 3164.3750 - ac_metrics: 0.61 - ETA: 16:20 - loss: 3161.7163 - ac_metrics: 0.61 - ETA: 16:16 - loss: 3155.3555 - ac_metrics: 0.61 - ETA: 16:12 - loss: 3154.5535 - ac_metrics: 0.61 - ETA: 16:08 - loss: 3157.6865 - ac_metrics: 0.61 - ETA: 16:05 - loss: 3160.1177 - ac_metrics: 0.61 - ETA: 16:01 - loss: 3166.1907 - ac_metrics: 0.61 - ETA: 15:57 - loss: 3165.3257 - ac_metrics: 0.61 - ETA: 15:54 - loss: 3166.2026 - ac_metrics: 0.61 - ETA: 15:50 - loss: 3178.4956 - ac_metrics: 0.61 - ETA: 15:46 - loss: 3179.3450 - ac_metrics: 0.61 - ETA: 15:42 - loss: 3182.5422 - ac_metrics: 0.61 - ETA: 15:39 - loss: 3185.9292 - ac_metrics: 0.61 - ETA: 15:35 - loss: 3187.6980 - ac_metrics: 0.61 - ETA: 15:31 - loss: 3181.5037 - ac_metrics: 0.62 - ETA: 15:27 - loss: 3175.8730 - ac_metrics: 0.62 - ETA: 15:24 - loss: 3174.2036 - ac_metrics: 0.62 - ETA: 15:20 - loss: 3169.7075 - ac_metrics: 0.62 - ETA: 15:16 - loss: 3166.6692 - ac_metrics: 0.62 - ETA: 15:13 - loss: 3165.9817 - ac_metrics: 0.62 - ETA: 15:09 - loss: 3165.5989 - ac_metrics: 0.62 - ETA: 15:05 - loss: 3162.3975 - ac_metrics: 0.62 - ETA: 15:01 - loss: 3158.2104 - ac_metrics: 0.62 - ETA: 14:58 - loss: 3158.2993 - ac_metrics: 0.62 - ETA: 14:54 - loss: 3155.8040 - ac_metrics: 0.62 - ETA: 14:50 - loss: 3152.6858 - ac_metrics: 0.62 - ETA: 14:46 - loss: 3153.3418 - ac_metrics: 0.62 - ETA: 14:43 - loss: 3158.0037 - ac_metrics: 0.62 - ETA: 14:39 - loss: 3164.2039 - ac_metrics: 0.62 - ETA: 14:35 - loss: 3161.8994 - ac_metrics: 0.62 - ETA: 14:31 - loss: 3163.6958 - ac_metrics: 0.63 - ETA: 14:28 - loss: 3159.4812 - ac_metrics: 0.63 - ETA: 14:24 - loss: 3157.6074 - ac_metrics: 0.63 - ETA: 14:20 - loss: 3154.9478 - ac_metrics: 0.63 - ETA: 14:16 - loss: 3153.5071 - ac_metrics: 0.63 - ETA: 14:13 - loss: 3148.1902 - ac_metrics: 0.63 - ETA: 14:09 - loss: 3150.4985 - ac_metrics: 0.63 - ETA: 14:05 - loss: 3152.4375 - ac_metrics: 0.63 - ETA: 14:01 - loss: 3146.7412 - ac_metrics: 0.63 - ETA: 13:58 - loss: 3148.7432 - ac_metrics: 0.63 - ETA: 13:54 - loss: 3149.2976 - ac_metrics: 0.63 - ETA: 13:50 - loss: 3154.4082 - ac_metrics: 0.6370"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/383 [========================>.....] - ETA: 13:46 - loss: 3156.5535 - ac_metrics: 0.63 - ETA: 13:43 - loss: 3154.0234 - ac_metrics: 0.63 - ETA: 13:39 - loss: 3157.5559 - ac_metrics: 0.63 - ETA: 13:35 - loss: 3156.3374 - ac_metrics: 0.63 - ETA: 13:31 - loss: 3156.0483 - ac_metrics: 0.63 - ETA: 13:28 - loss: 3158.2039 - ac_metrics: 0.63 - ETA: 13:24 - loss: 3160.4314 - ac_metrics: 0.63 - ETA: 13:20 - loss: 3158.5474 - ac_metrics: 0.63 - ETA: 13:17 - loss: 3159.3379 - ac_metrics: 0.64 - ETA: 13:13 - loss: 3166.2126 - ac_metrics: 0.64 - ETA: 13:09 - loss: 3167.4543 - ac_metrics: 0.64 - ETA: 13:05 - loss: 3165.7036 - ac_metrics: 0.64 - ETA: 13:02 - loss: 3172.8943 - ac_metrics: 0.64 - ETA: 12:58 - loss: 3171.2112 - ac_metrics: 0.64 - ETA: 12:54 - loss: 3166.5056 - ac_metrics: 0.64 - ETA: 12:51 - loss: 3165.7107 - ac_metrics: 0.64 - ETA: 12:47 - loss: 3165.6504 - ac_metrics: 0.64 - ETA: 12:43 - loss: 3163.3623 - ac_metrics: 0.64 - ETA: 12:39 - loss: 3165.3132 - ac_metrics: 0.64 - ETA: 12:36 - loss: 3160.3838 - ac_metrics: 0.64 - ETA: 12:32 - loss: 3158.0527 - ac_metrics: 0.64 - ETA: 12:28 - loss: 3152.3525 - ac_metrics: 0.64 - ETA: 12:25 - loss: 3151.0420 - ac_metrics: 0.64 - ETA: 12:21 - loss: 3152.5876 - ac_metrics: 0.64 - ETA: 12:17 - loss: 3154.1519 - ac_metrics: 0.64 - ETA: 12:13 - loss: 3152.6064 - ac_metrics: 0.64 - ETA: 12:10 - loss: 3155.6091 - ac_metrics: 0.64 - ETA: 12:06 - loss: 3156.2388 - ac_metrics: 0.64 - ETA: 12:02 - loss: 3157.1433 - ac_metrics: 0.64 - ETA: 11:58 - loss: 3160.5330 - ac_metrics: 0.64 - ETA: 11:55 - loss: 3159.8054 - ac_metrics: 0.64 - ETA: 11:51 - loss: 3156.5911 - ac_metrics: 0.64 - ETA: 11:47 - loss: 3159.8147 - ac_metrics: 0.64 - ETA: 11:43 - loss: 3158.7205 - ac_metrics: 0.64 - ETA: 11:40 - loss: 3156.9973 - ac_metrics: 0.64 - ETA: 11:36 - loss: 3152.8342 - ac_metrics: 0.64 - ETA: 11:32 - loss: 3147.3176 - ac_metrics: 0.64 - ETA: 11:28 - loss: 3148.4790 - ac_metrics: 0.64 - ETA: 11:25 - loss: 3147.8345 - ac_metrics: 0.64 - ETA: 11:21 - loss: 3145.1597 - ac_metrics: 0.65 - ETA: 11:17 - loss: 3143.2175 - ac_metrics: 0.65 - ETA: 11:13 - loss: 3139.9026 - ac_metrics: 0.65 - ETA: 11:10 - loss: 3139.1658 - ac_metrics: 0.65 - ETA: 11:06 - loss: 3136.7744 - ac_metrics: 0.65 - ETA: 11:02 - loss: 3136.8196 - ac_metrics: 0.64 - ETA: 10:58 - loss: 3136.5896 - ac_metrics: 0.64 - ETA: 10:55 - loss: 3137.2947 - ac_metrics: 0.65 - ETA: 10:51 - loss: 3137.0374 - ac_metrics: 0.65 - ETA: 10:47 - loss: 3145.6411 - ac_metrics: 0.65 - ETA: 10:43 - loss: 3146.5422 - ac_metrics: 0.65 - ETA: 10:39 - loss: 3142.4346 - ac_metrics: 0.64 - ETA: 10:36 - loss: 3142.3088 - ac_metrics: 0.64 - ETA: 10:32 - loss: 3141.0454 - ac_metrics: 0.64 - ETA: 10:28 - loss: 3141.2905 - ac_metrics: 0.64 - ETA: 10:24 - loss: 3142.0911 - ac_metrics: 0.64 - ETA: 10:21 - loss: 3143.7183 - ac_metrics: 0.64 - ETA: 10:17 - loss: 3141.6096 - ac_metrics: 0.64 - ETA: 10:13 - loss: 3141.3486 - ac_metrics: 0.64 - ETA: 10:09 - loss: 3142.4727 - ac_metrics: 0.64 - ETA: 10:05 - loss: 3144.7690 - ac_metrics: 0.64 - ETA: 10:02 - loss: 3144.6021 - ac_metrics: 0.64 - ETA: 9:58 - loss: 3140.6636 - ac_metrics: 0.6473 - ETA: 9:54 - loss: 3140.0144 - ac_metrics: 0.646 - ETA: 9:50 - loss: 3136.8599 - ac_metrics: 0.647 - ETA: 9:47 - loss: 3136.5510 - ac_metrics: 0.647 - ETA: 9:43 - loss: 3135.1978 - ac_metrics: 0.647 - ETA: 9:39 - loss: 3134.9175 - ac_metrics: 0.646 - ETA: 9:35 - loss: 3135.5063 - ac_metrics: 0.646 - ETA: 9:31 - loss: 3132.3289 - ac_metrics: 0.646 - ETA: 9:28 - loss: 3129.5518 - ac_metrics: 0.646 - ETA: 9:24 - loss: 3128.7578 - ac_metrics: 0.646 - ETA: 9:20 - loss: 3126.8721 - ac_metrics: 0.646 - ETA: 9:16 - loss: 3127.5195 - ac_metrics: 0.647 - ETA: 9:13 - loss: 3126.0349 - ac_metrics: 0.646 - ETA: 9:09 - loss: 3123.0808 - ac_metrics: 0.646 - ETA: 9:05 - loss: 3121.4360 - ac_metrics: 0.646 - ETA: 9:01 - loss: 3119.0583 - ac_metrics: 0.646 - ETA: 8:57 - loss: 3125.2251 - ac_metrics: 0.647 - ETA: 8:54 - loss: 3125.9324 - ac_metrics: 0.646 - ETA: 8:50 - loss: 3125.1021 - ac_metrics: 0.646 - ETA: 8:46 - loss: 3124.1333 - ac_metrics: 0.647 - ETA: 8:42 - loss: 3122.1111 - ac_metrics: 0.647 - ETA: 8:38 - loss: 3124.8098 - ac_metrics: 0.646 - ETA: 8:35 - loss: 3122.6831 - ac_metrics: 0.647 - ETA: 8:31 - loss: 3123.5076 - ac_metrics: 0.646 - ETA: 8:27 - loss: 3123.3093 - ac_metrics: 0.647 - ETA: 8:23 - loss: 3122.7061 - ac_metrics: 0.646 - ETA: 8:20 - loss: 3124.0774 - ac_metrics: 0.646 - ETA: 8:16 - loss: 3123.6162 - ac_metrics: 0.646 - ETA: 8:12 - loss: 3122.2859 - ac_metrics: 0.645 - ETA: 8:08 - loss: 3118.9521 - ac_metrics: 0.645 - ETA: 8:04 - loss: 3117.4878 - ac_metrics: 0.645 - ETA: 8:01 - loss: 3115.4934 - ac_metrics: 0.645 - ETA: 7:57 - loss: 3118.4324 - ac_metrics: 0.646 - ETA: 7:53 - loss: 3115.2822 - ac_metrics: 0.646 - ETA: 7:49 - loss: 3116.3416 - ac_metrics: 0.646 - ETA: 7:45 - loss: 3116.6716 - ac_metrics: 0.646 - ETA: 7:42 - loss: 3114.9417 - ac_metrics: 0.645 - ETA: 7:38 - loss: 3115.0474 - ac_metrics: 0.646 - ETA: 7:34 - loss: 3115.8545 - ac_metrics: 0.646 - ETA: 7:30 - loss: 3115.4890 - ac_metrics: 0.646 - ETA: 7:26 - loss: 3112.9688 - ac_metrics: 0.646 - ETA: 7:23 - loss: 3111.6455 - ac_metrics: 0.645 - ETA: 7:19 - loss: 3112.6294 - ac_metrics: 0.646 - ETA: 7:15 - loss: 3109.2527 - ac_metrics: 0.646 - ETA: 7:11 - loss: 3108.5500 - ac_metrics: 0.646 - ETA: 7:07 - loss: 3108.8528 - ac_metrics: 0.645 - ETA: 7:04 - loss: 3109.1724 - ac_metrics: 0.645 - ETA: 7:00 - loss: 3107.5042 - ac_metrics: 0.645 - ETA: 6:56 - loss: 3105.6907 - ac_metrics: 0.645 - ETA: 6:52 - loss: 3103.2297 - ac_metrics: 0.645 - ETA: 6:48 - loss: 3103.2678 - ac_metrics: 0.646 - ETA: 6:45 - loss: 3102.8928 - ac_metrics: 0.646 - ETA: 6:41 - loss: 3100.4622 - ac_metrics: 0.645 - ETA: 6:37 - loss: 3100.0071 - ac_metrics: 0.645 - ETA: 6:33 - loss: 3098.9243 - ac_metrics: 0.645 - ETA: 6:29 - loss: 3099.8572 - ac_metrics: 0.646 - ETA: 6:26 - loss: 3099.9138 - ac_metrics: 0.645 - ETA: 6:22 - loss: 3099.6995 - ac_metrics: 0.645 - ETA: 6:18 - loss: 3100.0540 - ac_metrics: 0.644 - ETA: 6:14 - loss: 3099.7859 - ac_metrics: 0.645 - ETA: 6:10 - loss: 3097.5015 - ac_metrics: 0.645 - ETA: 6:06 - loss: 3099.6719 - ac_metrics: 0.646 - ETA: 6:03 - loss: 3098.7544 - ac_metrics: 0.646 - ETA: 5:59 - loss: 3099.1768 - ac_metrics: 0.645 - ETA: 5:55 - loss: 3096.8379 - ac_metrics: 0.645 - ETA: 5:51 - loss: 3096.6621 - ac_metrics: 0.645 - ETA: 5:47 - loss: 3093.7202 - ac_metrics: 0.645 - ETA: 5:44 - loss: 3096.7676 - ac_metrics: 0.644 - ETA: 5:40 - loss: 3099.4495 - ac_metrics: 0.644 - ETA: 5:36 - loss: 3098.1812 - ac_metrics: 0.645 - ETA: 5:32 - loss: 3097.5662 - ac_metrics: 0.644 - ETA: 5:28 - loss: 3096.7598 - ac_metrics: 0.644 - ETA: 5:25 - loss: 3095.7583 - ac_metrics: 0.644 - ETA: 5:21 - loss: 3094.3987 - ac_metrics: 0.645 - ETA: 5:17 - loss: 3092.9436 - ac_metrics: 0.645 - ETA: 5:13 - loss: 3093.3130 - ac_metrics: 0.645 - ETA: 5:09 - loss: 3092.3398 - ac_metrics: 0.645 - ETA: 5:05 - loss: 3091.9985 - ac_metrics: 0.644 - ETA: 5:02 - loss: 3090.9124 - ac_metrics: 0.644 - ETA: 4:58 - loss: 3089.7661 - ac_metrics: 0.644 - ETA: 4:54 - loss: 3089.0549 - ac_metrics: 0.644 - ETA: 4:50 - loss: 3091.4697 - ac_metrics: 0.644 - ETA: 4:46 - loss: 3088.5134 - ac_metrics: 0.645 - ETA: 4:43 - loss: 3087.1101 - ac_metrics: 0.645 - ETA: 4:39 - loss: 3087.5083 - ac_metrics: 0.645 - ETA: 4:35 - loss: 3084.9563 - ac_metrics: 0.645 - ETA: 4:31 - loss: 3090.0562 - ac_metrics: 0.646 - ETA: 4:27 - loss: 3089.9023 - ac_metrics: 0.645 - ETA: 4:24 - loss: 3089.9148 - ac_metrics: 0.646 - ETA: 4:20 - loss: 3092.1721 - ac_metrics: 0.647 - ETA: 4:16 - loss: 3091.9792 - ac_metrics: 0.648 - ETA: 4:12 - loss: 3092.2927 - ac_metrics: 0.648 - ETA: 4:08 - loss: 3093.2588 - ac_metrics: 0.648 - ETA: 4:04 - loss: 3093.7371 - ac_metrics: 0.647 - ETA: 4:01 - loss: 3091.9241 - ac_metrics: 0.647 - ETA: 3:57 - loss: 3092.0930 - ac_metrics: 0.648 - ETA: 3:53 - loss: 3090.9482 - ac_metrics: 0.648 - ETA: 3:49 - loss: 3090.5752 - ac_metrics: 0.648 - ETA: 3:45 - loss: 3089.7747 - ac_metrics: 0.647 - ETA: 3:42 - loss: 3089.2192 - ac_metrics: 0.647 - ETA: 3:38 - loss: 3087.4751 - ac_metrics: 0.647 - ETA: 3:34 - loss: 3086.2751 - ac_metrics: 0.647 - ETA: 3:30 - loss: 3086.3987 - ac_metrics: 0.6478"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 3:26 - loss: 3086.2478 - ac_metrics: 0.647 - ETA: 3:22 - loss: 3087.9927 - ac_metrics: 0.647 - ETA: 3:19 - loss: 3088.2471 - ac_metrics: 0.647 - ETA: 3:15 - loss: 3087.4541 - ac_metrics: 0.646 - ETA: 3:11 - loss: 3085.6831 - ac_metrics: 0.646 - ETA: 3:07 - loss: 3086.1162 - ac_metrics: 0.645 - ETA: 3:03 - loss: 3086.2603 - ac_metrics: 0.645 - ETA: 2:59 - loss: 3085.9402 - ac_metrics: 0.645 - ETA: 2:56 - loss: 3084.1743 - ac_metrics: 0.646 - ETA: 2:52 - loss: 3084.2305 - ac_metrics: 0.646 - ETA: 2:48 - loss: 3083.4424 - ac_metrics: 0.646 - ETA: 2:44 - loss: 3082.9905 - ac_metrics: 0.645 - ETA: 2:40 - loss: 3083.1130 - ac_metrics: 0.645 - ETA: 2:37 - loss: 3082.0823 - ac_metrics: 0.645 - ETA: 2:33 - loss: 3081.7405 - ac_metrics: 0.645 - ETA: 2:29 - loss: 3081.5730 - ac_metrics: 0.645 - ETA: 2:25 - loss: 3079.8193 - ac_metrics: 0.645 - ETA: 2:21 - loss: 3079.8838 - ac_metrics: 0.645 - ETA: 2:17 - loss: 3079.5564 - ac_metrics: 0.645 - ETA: 2:14 - loss: 3079.6594 - ac_metrics: 0.645 - ETA: 2:10 - loss: 3080.1316 - ac_metrics: 0.646 - ETA: 2:06 - loss: 3080.8782 - ac_metrics: 0.646 - ETA: 2:02 - loss: 3081.2068 - ac_metrics: 0.646 - ETA: 1:58 - loss: 3079.5823 - ac_metrics: 0.645 - ETA: 1:54 - loss: 3080.9431 - ac_metrics: 0.645 - ETA: 1:51 - loss: 3078.3572 - ac_metrics: 0.646 - ETA: 1:47 - loss: 3080.2297 - ac_metrics: 0.645 - ETA: 1:43 - loss: 3081.0190 - ac_metrics: 0.645 - ETA: 1:39 - loss: 3081.3054 - ac_metrics: 0.645 - ETA: 1:35 - loss: 3080.9773 - ac_metrics: 0.645 - ETA: 1:31 - loss: 3081.0027 - ac_metrics: 0.645 - ETA: 1:28 - loss: 3080.5950 - ac_metrics: 0.644 - ETA: 1:24 - loss: 3078.5950 - ac_metrics: 0.645 - ETA: 1:20 - loss: 3077.0544 - ac_metrics: 0.645 - ETA: 1:16 - loss: 3076.0378 - ac_metrics: 0.645 - ETA: 1:12 - loss: 3075.8240 - ac_metrics: 0.645 - ETA: 1:08 - loss: 3074.7979 - ac_metrics: 0.645 - ETA: 1:05 - loss: 3074.3015 - ac_metrics: 0.645 - ETA: 1:01 - loss: 3074.9409 - ac_metrics: 0.645 - ETA: 57s - loss: 3075.4983 - ac_metrics: 0.646 - ETA: 53s - loss: 3073.6541 - ac_metrics: 0.64 - ETA: 49s - loss: 3073.4312 - ac_metrics: 0.64 - ETA: 45s - loss: 3072.9229 - ac_metrics: 0.64 - ETA: 42s - loss: 3072.0083 - ac_metrics: 0.64 - ETA: 38s - loss: 3070.5259 - ac_metrics: 0.64 - ETA: 34s - loss: 3070.7476 - ac_metrics: 0.64 - ETA: 30s - loss: 3071.2234 - ac_metrics: 0.64 - ETA: 26s - loss: 3071.1814 - ac_metrics: 0.64 - ETA: 22s - loss: 3069.7332 - ac_metrics: 0.64 - ETA: 19s - loss: 3068.5874 - ac_metrics: 0.64 - ETA: 15s - loss: 3068.1838 - ac_metrics: 0.64 - ETA: 11s - loss: 3066.9709 - ac_metrics: 0.64 - ETA: 7s - loss: 3068.1226 - ac_metrics: 0.6481 - ETA: 3s - loss: 3068.3574 - ac_metrics: 0.648 - ETA: 0s - loss: 3066.5916 - ac_metrics: 0.648 - 1529s 4s/step - loss: 3066.5916 - ac_metrics: 0.6481 - val_loss: 2785.9407 - val_ac_metrics: 0.6699\n"
     ]
    }
   ],
   "source": [
    "history = kpe_model.fit([x_train[1000:],x_mask[1000:],x_pos[1000:]], y_train[1000:,:,0], \n",
    "                          batch_size=36,epochs=1,#callbacks=callbacks_list, \n",
    "                          #use_multiprocessing=True, \n",
    "                         validation_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['ac_metrics'])\n",
    "plt.plot(history.history['val_ac_metrics'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for test\n",
      "predictions shape: (500, 258, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for test\")\n",
    "predictions = kpe_model.predict([x_train[:500],x_mask[:500],x_pos[:500]])\n",
    "print(\"predictions shape:\", predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 [0.05293348 0.06307821 0.06892498] [0.05416667 0.0511627  0.05116007] [0.07254705 0.13008821 0.17917682]\n"
     ]
    }
   ],
   "source": [
    "calculate_f1(np.where(y_train[:500,:,0]-1==1,1,0),predictions[:,:,0],25,[5,10,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./checkpoints/KP20/kp20_final\\assets\n"
     ]
    }
   ],
   "source": [
    "kpe_model.save('./checkpoints/KP20/kp20_final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 22, 23, 24, 25, 26, 28], dtype=int64),)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 198\n",
    "np.where(predictions[t,:,0][np.where((y_train[t,:,0])>0)]>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  18,   4,   2,   1,  25,  24,  20,  11,  14,  23,  28,   7,\n",
       "        17,  13,  10,   9,  15,  22,   0,  26,   8,   5,  19,  12,  16,\n",
       "        21,  29,  27,   6,  32,  33,  37,  34,  53,  54,  52,  55,  56,\n",
       "        51,  57,  50,  58,  49,  59,  60,  48,  61,  47,  62,  31,  46,\n",
       "        63,  30,  64,  45,  65,  44,  66,  35,  36,  43,  67,  68,  42,\n",
       "        69,  41,  70,  40,  71,  39,  38,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 257, 113, 114, 256,\n",
       "       115, 116, 255, 117, 118, 254, 119, 120, 253, 121, 122, 252, 123,\n",
       "       124, 251, 125, 126, 250, 127, 128, 249, 129, 130, 248, 131, 132,\n",
       "       247, 133, 246, 134, 135, 245, 136, 137, 244, 138, 139, 243, 140,\n",
       "       141, 242, 142, 143, 241, 144, 145, 240, 146, 147, 148, 239, 149,\n",
       "       150, 151, 238, 152, 153, 154, 155, 237, 156, 157, 158, 159, 236,\n",
       "       160, 161, 162, 163, 164, 235, 165, 166, 167, 168, 169, 234, 170,\n",
       "       171, 172, 173, 233, 174, 175, 176, 177, 178, 232, 179, 180, 181,\n",
       "       182, 231, 183, 184, 185, 186, 230, 187, 188, 189, 190, 229, 191,\n",
       "       192, 193, 228, 194, 195, 196, 197, 227, 198, 226, 199, 200, 201,\n",
       "       225, 202, 203, 224, 205, 204, 223, 206, 207, 208, 222, 209, 210,\n",
       "       211, 221, 220, 212, 218, 217, 215, 214, 213, 219, 216], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-predictions[t,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18], dtype=int64),)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((y_train[t,:,0]-1)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parametric models for sequential data such as hidden markov models stochastic contextfree grammars and linear dynamical systems are widely used in timeseries analysis and structural data analysis computation of the likelihood function is one of primary considerations in many learning methods iterative calculation of the likelihood such as the model selection is still timeconsuming though there are effective algorithms based on dynamic programming the present paper studies parameter learning in a simplified feature space to reduce the computational cost simplifying data is a common technique seen in feature selection and dimension reduction though an oversimplified space causes adverse learning results therefore we mathematically investigate a condition of the feature map to have an asymptotically equivalent convergence point of estimated parameters referred to as the vicarious map as a demonstration to find vicarious maps we consider the feature space which limits the length of data and derive a necessary length for parameter learning in hidden markov models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'learning': 0.5971708,\n",
       "             'feature selection': 0.580973,\n",
       "             'feature space': 0.5754552,\n",
       "             'timeseries analysis': 0.56864053,\n",
       "             'dimension reduction': 0.5616109,\n",
       "             'dynamic programming': 0.5573249,\n",
       "             'length': 0.55653286,\n",
       "             'vicarious map': 0.5516192,\n",
       "             'condition': 0.5503541,\n",
       "             'equivalent convergence point': 0.54687923,\n",
       "             'demonstration': 0.5431143,\n",
       "             'linear dynamical systems': 0.5389345,\n",
       "             'likelihood': 0.53707206,\n",
       "             'adverse learning': 0.5360124,\n",
       "             'sequential data': 0.5341229,\n",
       "             'timeconsuming': 0.5260348,\n",
       "             'common technique': 0.5251576,\n",
       "             'simplified feature space': 0.5241617,\n",
       "             'data': 0.5188727,\n",
       "             'many learning': 0.516537,\n",
       "             'parameters': 0.5082375,\n",
       "             'vicarious maps': 0.50619435})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t = 123\n",
    "idx = np.argsort(-predictions[t,:,0])\n",
    "preds = np.where(predictions[t,np.argsort(-predictions[t,:,0])]>=0.5)\n",
    "scores = predictions [t,idx]\n",
    "res = np.array(x_pos[t])[:,idx[preds[0]]]\n",
    "text = tokenizer.decode(list(tf.cast(x_train[t,:],dtype='int32')))\n",
    "print(text)\n",
    "keyphrases = collections.defaultdict(float)\n",
    "for i in range(res.shape[1]):\n",
    "    phrase = res[:,i]\n",
    "    phrase = tokenizer.decode(list(tf.cast(x_train[t,phrase[0]:(phrase[1]+1)],dtype='int32')))\n",
    "    keyphrases[phrase] = max(keyphrases[phrase],scores[i][0])\n",
    "\n",
    "keyphrases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
