{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF-TextRank.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKjRFJvqWaNm",
        "outputId": "0bfa1c87-1b74-4864-b94f-a4a6d3e17a83"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import operator\n",
        "import six\n",
        "from six.moves import range\n",
        "import math\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "stopwords = stopwords.words('english')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import spacy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9T6QDJ_U_n6"
      },
      "source": [
        "# TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCjsNRFTU9zi"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def textProcessing(doc):\n",
        "    '''Prepocessing of input text with \n",
        "    1. tokenisation and Lemmatisation\n",
        "    2. Removing stop words \n",
        "    3. Creating and removing custom stop words.\n",
        "    4. Generating required Vocabulary from input\n",
        "    5. Preprocessing the input \n",
        "    '''\n",
        "    Nouns = []\n",
        "    Noun_set = []\n",
        "    trimmed_noun_set = []\n",
        "    removing_duplicates = []\n",
        "    arr = []\n",
        "    vocab = []\n",
        "    vocab_dict = {}\n",
        "\n",
        "    doc = nlp(doc.lower())\n",
        "\n",
        "    for possible_nouns in doc:\n",
        "        if possible_nouns.pos_ in [\"NOUN\",\"PROPN\"] :\n",
        "            Nouns.append([possible_nouns , [child for child in possible_nouns.children]])\n",
        "       \n",
        "    \n",
        "    for i,j in Nouns:\n",
        "        for k in j:\n",
        "            Noun_set.append([k,i])\n",
        "\n",
        "    \n",
        "    for i , j in Noun_set:\n",
        "        if i.pos_ in ['PROPN','NOUN','ADJ']:\n",
        "            trimmed_noun_set.append([i ,j])\n",
        "            \n",
        "    \n",
        "    for word in trimmed_noun_set:\n",
        "        if word not in removing_duplicates:\n",
        "            removing_duplicates.append(word)\n",
        "    \n",
        "    \n",
        "    for i in removing_duplicates:\n",
        "        strs = ''\n",
        "        for j in i:\n",
        "            strs += str(j)+\" \"\n",
        "        arr.append(strs.strip())\n",
        "\n",
        "    \n",
        "    for word in Noun_set:\n",
        "        string = ''\n",
        "        for j in word:\n",
        "            string+= str(j)+ \" \"\n",
        "        vocab.append(string.strip())\n",
        "\n",
        "    \n",
        "    for word in vocab:\n",
        "        vocab_dict[word]= 0\n",
        "        \n",
        "    for word in arr:\n",
        "        vocab_dict[word]+= 1\n",
        "\n",
        "    return vocab_dict , arr\n",
        "\n",
        "def computeTF(wordDict,bow):\n",
        "    '''Computing TF(Term Frequency of the vocab) '''\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict\n",
        "\n",
        "\n",
        "def computeIDF(doclist):\n",
        "    '''Computing IDF for the vocab '''\n",
        "    import math \n",
        "    count = 0\n",
        "    idfDict = {}\n",
        "    for element in doclist:\n",
        "        for j in element:\n",
        "            count+=1\n",
        "    N = count\n",
        "\n",
        "    # count no of documents that contain the word w\n",
        "    idfDict = dict.fromkeys(doclist[0].keys(),0)\n",
        "\n",
        "    for doc in doclist:\n",
        "        for word,val in doc.items():\n",
        "            if val>0:\n",
        "                idfDict[word]+= 1\n",
        "\n",
        "    # divide N by denominator above\n",
        "    for word,val in idfDict.items():\n",
        "        if val == 0:\n",
        "            idfDict[word] = 0.0\n",
        "        else:\n",
        "            idfDict[word] = math.log(N / float(val))\n",
        "\n",
        "    return idfDict\n",
        "\n",
        "def computeTfidf(tf,idf):\n",
        "    '''Computing TF-IDF for the words in text '''\n",
        "    tfidf = {}\n",
        "    sorted_list = []\n",
        "    for word , val in tf.items():\n",
        "        tfidf[word] = val * idf[word]\n",
        "\n",
        "    ranking_list  = sorted(tfidf.items(),reverse=True, key = lambda kv:(kv[1], kv[0]))[:10]\n",
        "    for i, _ in ranking_list:\n",
        "        sorted_list.append(i)\n",
        "\n",
        "    return ','.join([str(elem) for elem in sorted_list])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLIqXMjEkV5A"
      },
      "source": [
        "def normalize_answer(s):\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    return ' '.join([lower(x) for x in s]).rstrip()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtuSQQZ8kReX"
      },
      "source": [
        "def remove_empty(a_list):\n",
        "    new_list = []\n",
        "    for i in a_list:\n",
        "        if len(i) > 0:\n",
        "            if len(i[0]) >0:\n",
        "                new_list.append(normalize_answer(i))   \n",
        "    return new_list"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjM9QNnBkq0g"
      },
      "source": [
        "def get_score_full(candidates, references, maxDepth = 30):\n",
        "    precision = []\n",
        "    recall = []\n",
        "    reference_set = set(dedup(references))\n",
        "    candidates = dedup(candidates)\n",
        "    referencelen = len(reference_set)\n",
        "    true_positive = 0\n",
        "    for i in range(maxDepth):\n",
        "        if len(candidates) > i:\n",
        "            kp_pred = candidates[i]     \n",
        "            if kp_pred in reference_set:\n",
        "                true_positive += 1\n",
        "        precision.append(true_positive/float(i + 1))\n",
        "        recall.append(true_positive/float(referencelen))\n",
        "    return precision, recall"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nw84dtnkyQ3"
      },
      "source": [
        "def dedup(kp_list):\n",
        "    dedupset = set()\n",
        "    kp_list_dedup = []\n",
        "    for kp in kp_list:\n",
        "        if kp in dedupset:\n",
        "            continue       \n",
        "        kp_list_dedup.append(kp)\n",
        "        dedupset.add(kp)\n",
        "    return kp_list_dedup"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbeSkoDkWHLT"
      },
      "source": [
        "def evaluate(candidates, references, data):\n",
        "    precision_scores, recall_scores, f1_scores = {1:[], 3:[], 5:[], 10:[], 30:[]}, {1:[], 3:[], 5:[], 10:[], 30:[]}, {1:[], 3:[], 5:[], 10:[], 30:[]}\n",
        "    for url in range(len(data)):\n",
        "        candidate = remove_empty(candidates.iloc[url])\n",
        "        reference = remove_empty(references.iloc[url])\n",
        "        p, r = get_score_full(candidate, reference) \n",
        "        for i in [1,3,5,10,30]:\n",
        "            precision = p[i-1]\n",
        "            recall = r[i-1]\n",
        "            if precision + recall > 0:\n",
        "                f1_scores[i].append((2 * (precision * recall)) / (precision + recall))\n",
        "            else:\n",
        "                f1_scores[i].append(0)\n",
        "            precision_scores[i].append(precision)\n",
        "            recall_scores[i].append(recall)\n",
        "    print(\"########################\\nMetrics\")\n",
        "    for i in precision_scores:\n",
        "        print(\"@{}\".format(i))\n",
        "        print(\"F1:{}\".format(np.mean(f1_scores[i])))\n",
        "        print(\"P:{}\".format(np.mean(precision_scores[i])))\n",
        "        print(\"R:{}\".format(np.mean(recall_scores[i])))\n",
        "    print(\"#########################\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN329uIcVerK"
      },
      "source": [
        "### KP 20K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BPwerw_VcWE",
        "outputId": "4c03a3ee-4786-47a1-f72d-7ce349909206"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Colab Notebooks/Advanced NLP-Project/Project/kp20k_new.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/Advanced NLP-Project/Project/kp20k_new.zip\n",
            "  inflating: kp20k_testing.json      \n",
            "  inflating: kp20k_training.json     \n",
            "  inflating: kp20k_validation.json   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRORN2k1Vbr2"
      },
      "source": [
        "import json \n",
        "test = []\n",
        "for line in open('/content/kp20k_testing.json', 'r'):\n",
        "    test.append(json.loads(line))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbAewWFpVtvT"
      },
      "source": [
        "test_data = pd.DataFrame(test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6CAPkcoVtsX"
      },
      "source": [
        "test_data['keyword'] = test_data['keyword'].str.replace(';',',')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0WPvzehiWXXy",
        "outputId": "ccd8ed8c-c49d-4aff-a975-fc5395d3f409"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>keyword</th>\n",
              "      <th>title</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A feedback vertex set of a graph G is a set S ...</td>\n",
              "      <td>feedback vertex set,decycling set,2-degenerate...</td>\n",
              "      <td>A feedback vertex set of 2-degenerate graphs</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This article proposes techniques to predict th...</td>\n",
              "      <td>performance,analytical modeling,pending hit,da...</td>\n",
              "      <td>Hybrid Analytical Modeling of Pending Cache Hi...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Autoimmune polyendocrinopathy candidiasis ecto...</td>\n",
              "      <td>apeced,aire,chronic mucocutaneous candidiasis,...</td>\n",
              "      <td>Autoimmune polyendocrinopathy candidiasis ecto...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this paper, we consider an enthalpy formula...</td>\n",
              "      <td>casting,thermal,conduction,convection,finite e...</td>\n",
              "      <td>Numerical solution of a three-dimensional soli...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In this research, a new type of manufacturing ...</td>\n",
              "      <td>feature recognition,rib,aircraft structural pa...</td>\n",
              "      <td>Definition and recognition of rib features in ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Energy efficiency and transmission delay are v...</td>\n",
              "      <td>energy efficiency,delay,unreliable links,wirel...</td>\n",
              "      <td>Energy-delay tradeoff in wireless multihop net...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>This paper describes the design and implementa...</td>\n",
              "      <td>e-medical records,e-health,e-clinic,web-based,...</td>\n",
              "      <td>A Cyber Medical Center</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>This work describes a detailed simulation-base...</td>\n",
              "      <td>wireless lan,quality of service,medium access ...</td>\n",
              "      <td>adapting wlan mac parameters to enhance voip c...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>This paper describes a conceptually simple but...</td>\n",
              "      <td>interior point methods,ellipsoid method,multio...</td>\n",
              "      <td>An interior point multiobjective programming a...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>Most of the reports on the method of fundament...</td>\n",
              "      <td>method of fundamental solutions,method of part...</td>\n",
              "      <td>The method of fundamental solutions and its co...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                abstract  ... tfidf\n",
              "0      A feedback vertex set of a graph G is a set S ...  ...      \n",
              "1      This article proposes techniques to predict th...  ...      \n",
              "2      Autoimmune polyendocrinopathy candidiasis ecto...  ...      \n",
              "3      In this paper, we consider an enthalpy formula...  ...      \n",
              "4      In this research, a new type of manufacturing ...  ...      \n",
              "...                                                  ...  ...   ...\n",
              "19995  Energy efficiency and transmission delay are v...  ...      \n",
              "19996  This paper describes the design and implementa...  ...      \n",
              "19997  This work describes a detailed simulation-base...  ...      \n",
              "19998  This paper describes a conceptually simple but...  ...      \n",
              "19999  Most of the reports on the method of fundament...  ...      \n",
              "\n",
              "[20000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7X1QjbAYIsp"
      },
      "source": [
        "tfidf_lst = []\n",
        "for i in test_data.abstract[0:5]:\n",
        "  vocab_dict , arr = textProcessing(i)\n",
        "  tf = computeTF(vocab_dict,arr)\n",
        "  idf = computeIDF([vocab_dict])\n",
        "  tfidf = computeTfidf(tf,idf)\n",
        "  tfidf_lst.append(tfidf)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLzvGzVaF0s"
      },
      "source": [
        "test_data['tfidf'] = ''"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm6jj7t-gPST"
      },
      "source": [
        "test_data_5 = test_data[0:5]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS7tbPTZGOu"
      },
      "source": [
        "%%time\n",
        "for key,val in enumerate(test_data_5.abstract):\n",
        "  try:\n",
        "    vocab_dict , arr = textProcessing(val)\n",
        "    tf = computeTF(vocab_dict,arr)\n",
        "    idf = computeIDF([vocab_dict])\n",
        "    tfidf = computeTfidf(tf,idf)\n",
        "    print(tfidf)\n",
        "    print('======')\n",
        "    test_data_5['tfidf'].loc[key] = tfidf\n",
        "  except ZeroDivisionError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kXe2kGNgyDx",
        "outputId": "3bc014be-2568-44f4-e37b-53228f14d5e5"
      },
      "source": [
        "%%time\n",
        "for key,val in enumerate(test_data.abstract):\n",
        "  try:\n",
        "    vocab_dict , arr = textProcessing(val)\n",
        "    tf = computeTF(vocab_dict,arr)\n",
        "    idf = computeIDF([vocab_dict])\n",
        "    tfidf = computeTfidf(tf,idf)\n",
        "    test_data['tfidf'].loc[key] = tfidf\n",
        "  except ZeroDivisionError:\n",
        "    pass"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 30s, sys: 2.92 s, total: 10min 33s\n",
            "Wall time: 10min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCvf6jlyW7eC"
      },
      "source": [
        "# vocab_dict , arr = textProcessing(text[0])\n",
        "# tf = computeTF(vocab_dict,arr)\n",
        "# idf = computeIDF([vocab_dict])\n",
        "# tfidf = computeTfidf(tf,idf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zGBVdYXVq7"
      },
      "source": [
        "#test_data['vocab_dict'],test_data['arr'] = test_data['abstract'].apply(lambda x : textProcessing(x))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "jzInr3VAhEeo",
        "outputId": "cec02400-b416-4166-afd2-ebf0924ac9e1"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>keyword</th>\n",
              "      <th>title</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A feedback vertex set of a graph G is a set S ...</td>\n",
              "      <td>feedback vertex set,decycling set,2-degenerate...</td>\n",
              "      <td>A feedback vertex set of 2-degenerate graphs</td>\n",
              "      <td>graph g,feedback vertex,vertex v,vertex set,ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This article proposes techniques to predict th...</td>\n",
              "      <td>performance,analytical modeling,pending hit,da...</td>\n",
              "      <td>Hybrid Analytical Modeling of Pending Cache Hi...</td>\n",
              "      <td>limited number,uniform latency,superscalar mic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Autoimmune polyendocrinopathy candidiasis ecto...</td>\n",
              "      <td>apeced,aire,chronic mucocutaneous candidiasis,...</td>\n",
              "      <td>Autoimmune polyendocrinopathy candidiasis ecto...</td>\n",
              "      <td>various diseases,several lessons,recessive dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this paper, we consider an enthalpy formula...</td>\n",
              "      <td>casting,thermal,conduction,convection,finite e...</td>\n",
              "      <td>Numerical solution of a three-dimensional soli...</td>\n",
              "      <td>stefan problem,phase problem,numerical results...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In this research, a new type of manufacturing ...</td>\n",
              "      <td>feature recognition,rib,aircraft structural pa...</td>\n",
              "      <td>Definition and recognition of rib features in ...</td>\n",
              "      <td>rib elements,local elements,structural parts,r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Energy efficiency and transmission delay are v...</td>\n",
              "      <td>energy efficiency,delay,unreliable links,wirel...</td>\n",
              "      <td>Energy-delay tradeoff in wireless multihop net...</td>\n",
              "      <td>energy efficiency,wireless networks,physical p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>This paper describes the design and implementa...</td>\n",
              "      <td>e-medical records,e-health,e-clinic,web-based,...</td>\n",
              "      <td>A Cyber Medical Center</td>\n",
              "      <td>medical center,medical records,traditional sys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>This work describes a detailed simulation-base...</td>\n",
              "      <td>wireless lan,quality of service,medium access ...</td>\n",
              "      <td>adapting wlan mac parameters to enhance voip c...</td>\n",
              "      <td>new scheme,wlan parameters,wlan network,wirele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>This paper describes a conceptually simple but...</td>\n",
              "      <td>interior point methods,ellipsoid method,multio...</td>\n",
              "      <td>An interior point multiobjective programming a...</td>\n",
              "      <td>wider range,uncertain information,traditional ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>Most of the reports on the method of fundament...</td>\n",
              "      <td>method of fundamental solutions,method of part...</td>\n",
              "      <td>The method of fundamental solutions and its co...</td>\n",
              "      <td>fundamental solutions,| c,particular solutions...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                abstract  ...                                              tfidf\n",
              "0      A feedback vertex set of a graph G is a set S ...  ...  graph g,feedback vertex,vertex v,vertex set,ve...\n",
              "1      This article proposes techniques to predict th...  ...  limited number,uniform latency,superscalar mic...\n",
              "2      Autoimmune polyendocrinopathy candidiasis ecto...  ...  various diseases,several lessons,recessive dis...\n",
              "3      In this paper, we consider an enthalpy formula...  ...  stefan problem,phase problem,numerical results...\n",
              "4      In this research, a new type of manufacturing ...  ...  rib elements,local elements,structural parts,r...\n",
              "...                                                  ...  ...                                                ...\n",
              "19995  Energy efficiency and transmission delay are v...  ...  energy efficiency,wireless networks,physical p...\n",
              "19996  This paper describes the design and implementa...  ...  medical center,medical records,traditional sys...\n",
              "19997  This work describes a detailed simulation-base...  ...  new scheme,wlan parameters,wlan network,wirele...\n",
              "19998  This paper describes a conceptually simple but...  ...  wider range,uncertain information,traditional ...\n",
              "19999  Most of the reports on the method of fundament...  ...  fundamental solutions,| c,particular solutions...\n",
              "\n",
              "[20000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qIl658okGG5",
        "outputId": "b59b744f-bfdd-4959-ff6e-efc434d08980"
      },
      "source": [
        "evaluate(test_data['tfidf'],test_data['keyword'],test_data)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########################\n",
            "Metrics\n",
            "@1\n",
            "F1:0.08285289412526706\n",
            "P:0.91\n",
            "R:0.04344140162474216\n",
            "@3\n",
            "F1:0.23565650575554\n",
            "P:0.9408333333333332\n",
            "R:0.13502992904701944\n",
            "@5\n",
            "F1:0.3642462818151996\n",
            "P:0.9460900000000001\n",
            "R:0.2264027117841467\n",
            "@10\n",
            "F1:0.6105036847025352\n",
            "P:0.94711\n",
            "R:0.45320779700101166\n",
            "@30\n",
            "F1:0.7550764557012816\n",
            "P:0.6452949999999998\n",
            "R:0.9193874406025488\n",
            "#########################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlZUGDIWVhwC"
      },
      "source": [
        "### Inspec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VOxqXB5VhEH"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/Advanced NLP-Project/Project/Inspec.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oscocbRGVhAr"
      },
      "source": [
        "data = '/content/Inspec/docsutf8/'\n",
        "keys = '/content/Inspec/keys/'\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roqwf6IVlCrN"
      },
      "source": [
        "files = os.listdir(data)\n",
        "key_files = os.listdir(keys)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXrx-MVWlCpK",
        "outputId": "5f94dce0-547f-4f8b-cfad-2132a5ce735c"
      },
      "source": [
        "len(files)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh4DITmrlCnE"
      },
      "source": [
        "text = []\n",
        "for file in files[:2000]:\n",
        "  with open('/content/Inspec/docsutf8/'+file, 'r') as in_file:\n",
        "    data = in_file.read()\n",
        "    text.append(data)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEoFTdMxl-qS"
      },
      "source": [
        "#candidates = []\n",
        "references = []\n",
        "\n",
        "for file in files[:2000]:\n",
        "    # with open(data+file, 'r') as in_file: \n",
        "    #     text = in_file.read()\n",
        "    #     candidates.append({'url':file,\n",
        "    #                         'KeyPhrases':get_kp(text)})\n",
        "    \n",
        "    name = file.split('.')[0]\n",
        "    with open(keys+name+'.key', 'r') as in_file:\n",
        "        can = in_file.readlines()\n",
        "        can = [line.rstrip('\\n').split() for line in can]\n",
        "        references.append(can)\n",
        "    \n",
        "\n",
        "\n",
        "# with open('result.json', 'w') as out_file:\n",
        "#     for candidate in candidates:\n",
        "#         json.dump(str(candidate), out_file)\n",
        "#         out_file.write('\\n')\n",
        "with open('keys.json', 'w') as out_file:\n",
        "    for ref in references:\n",
        "        json.dump(ref, out_file)\n",
        "        out_file.write('\\n')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCF248cEmBzx"
      },
      "source": [
        "ref_phrases = []\n",
        "for i in range(len(references)):\n",
        "  phrases = [' '.join(ref) for ref in references[i]]\n",
        "  ref_phrases.append(','.join(phrases))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9z1O3YYlCk_"
      },
      "source": [
        "inspec_data = pd.DataFrame(\n",
        "    {'text': text,\n",
        "     'keyword': ref_phrases\n",
        "    })"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "o0eLNGEalCiT",
        "outputId": "89e36661-9204-447c-93f6-16269920b9e1"
      },
      "source": [
        "inspec_data"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wavelet-based level-of-detail representation o...</td>\n",
              "      <td>3D object level of detail modeling system,wave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural networks in optimal filtration\\nThe com...</td>\n",
              "      <td>optimal filtering,neural networks,linear filte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A new high resolution color flow system using ...</td>\n",
              "      <td>high resolution colour flow system,eigendecomp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>New hub gears up for algorithmic exchange\\nWar...</td>\n",
              "      <td>Warwick University Centre for Scientific Compu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geometric source separation: merging convoluti...</td>\n",
              "      <td>geometric source separation,geometric beamform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Academic libraries and community: making the c...</td>\n",
              "      <td>academic libraries,community partnerships,camp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>CRONE control: principles and extension to tim...</td>\n",
              "      <td>CRONE control,time-variant plants,asymptotical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Mining the optimal class association rule set\\...</td>\n",
              "      <td>optimal class association rule set mining,mini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Dynamic testing of inflatable structures using...</td>\n",
              "      <td>thin-film torus,smart materials,satellite appl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>Structural interpretation of matched pole-zero...</td>\n",
              "      <td>structural interpretation,matched pole-zero di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text                                            keyword\n",
              "0     Wavelet-based level-of-detail representation o...  3D object level of detail modeling system,wave...\n",
              "1     Neural networks in optimal filtration\\nThe com...  optimal filtering,neural networks,linear filte...\n",
              "2     A new high resolution color flow system using ...  high resolution colour flow system,eigendecomp...\n",
              "3     New hub gears up for algorithmic exchange\\nWar...  Warwick University Centre for Scientific Compu...\n",
              "4     Geometric source separation: merging convoluti...  geometric source separation,geometric beamform...\n",
              "...                                                 ...                                                ...\n",
              "1995  Academic libraries and community: making the c...  academic libraries,community partnerships,camp...\n",
              "1996  CRONE control: principles and extension to tim...  CRONE control,time-variant plants,asymptotical...\n",
              "1997  Mining the optimal class association rule set\\...  optimal class association rule set mining,mini...\n",
              "1998  Dynamic testing of inflatable structures using...  thin-film torus,smart materials,satellite appl...\n",
              "1999  Structural interpretation of matched pole-zero...  structural interpretation,matched pole-zero di...\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLV2ZkCLlhRY"
      },
      "source": [
        "inspec_data['keyword'] = inspec_data['keyword'].str.lower()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgvIF5kUmqLg"
      },
      "source": [
        "inspec_data['tfidf'] = ''"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuf_pD3vmzyo",
        "outputId": "a7fde6f7-2f54-4e5f-d56f-976cb5b1c740"
      },
      "source": [
        "%%time\n",
        "for key,val in enumerate(inspec_data.text):\n",
        "  try:\n",
        "    vocab_dict , arr = textProcessing(val)\n",
        "    tf = computeTF(vocab_dict,arr)\n",
        "    idf = computeIDF([vocab_dict])\n",
        "    tfidf = computeTfidf(tf,idf)\n",
        "    inspec_data['tfidf'].loc[key] = tfidf\n",
        "  except ZeroDivisionError:\n",
        "    pass"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.2 s, sys: 421 ms, total: 58.6 s\n",
            "Wall time: 58.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56c42rScm0Wx",
        "outputId": "b1592fbc-2c67-43bf-eeae-3ef4012df990"
      },
      "source": [
        "evaluate(inspec_data['tfidf'],inspec_data['keyword'],inspec_data)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########################\n",
            "Metrics\n",
            "@1\n",
            "F1:0.07797659374394664\n",
            "P:0.9835\n",
            "R:0.0406180012396357\n",
            "@3\n",
            "F1:0.21771943279323885\n",
            "P:0.9883333333333333\n",
            "R:0.12250416721885322\n",
            "@5\n",
            "F1:0.3382105504391887\n",
            "P:0.9894\n",
            "R:0.20440563555366723\n",
            "@10\n",
            "F1:0.576926098316625\n",
            "P:0.989\n",
            "R:0.4087391400053235\n",
            "@30\n",
            "F1:0.7902624322314816\n",
            "P:0.7175333333333334\n",
            "R:0.8851759127346382\n",
            "#########################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgz7zQNhufsa"
      },
      "source": [
        "# TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BElyd5zue8S"
      },
      "source": [
        "def clean(text):\n",
        "    text = text.lower()\n",
        "    printable = set(string.printable)\n",
        "    text = filter(lambda x: x in printable, text)\n",
        "    text = \"\".join(list(text))\n",
        "    return text\n",
        "\n",
        "def TextScoring(text):\n",
        "  cleaned_text = clean(text)\n",
        "  text = word_tokenize(cleaned_text)\n",
        "  pos_tag = nltk.pos_tag(text)\n",
        "  wordnet_lemmatizer = WordNetLemmatizer()\n",
        "  adjective_tags = ['JJ','JJR','JJS']\n",
        "  lemmatized_text = []\n",
        "  for word in pos_tag:\n",
        "      if word[1] in adjective_tags:\n",
        "          lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0],pos=\"a\")))\n",
        "      else:\n",
        "          lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0])))\n",
        "  pos_tag = nltk.pos_tag(lemmatized_text)\n",
        "  stopwords = []\n",
        "  wanted_POS = ['NN','NNS','NNP','NNPS','JJ','JJR','JJS'] \n",
        "  for word in pos_tag:\n",
        "      if word[1] not in wanted_POS:\n",
        "          stopwords.append(word[0])\n",
        "  punctuations = list(str(string.punctuation))\n",
        "  stopwords = stopwords + punctuations\n",
        "  processed_text = []\n",
        "  for word in lemmatized_text:\n",
        "      if word not in stopwords:\n",
        "          processed_text.append(word)\n",
        "  vocabulary = list(set(processed_text))\n",
        "  vocab_len = len(vocabulary)\n",
        "\n",
        "  weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
        "\n",
        "  score = np.zeros((vocab_len),dtype=np.float32)\n",
        "  window_size = 3\n",
        "  covered_coocurrences = []\n",
        "\n",
        "  for i in range(0,vocab_len):\n",
        "      score[i]=1\n",
        "      for j in range(0,vocab_len):\n",
        "          if j==i:\n",
        "              weighted_edge[i][j]=0\n",
        "          else:\n",
        "              for window_start in range(0,(len(processed_text)-window_size)):\n",
        "                  \n",
        "                  window_end = window_start+window_size\n",
        "                  \n",
        "                  window = processed_text[window_start:window_end]\n",
        "                  \n",
        "                  if (vocabulary[i] in window) and (vocabulary[j] in window):\n",
        "                      \n",
        "                      index_of_i = window_start + window.index(vocabulary[i])\n",
        "                      index_of_j = window_start + window.index(vocabulary[j])\n",
        "                      \n",
        "                      # index_of_x is the absolute position of the xth term in the window \n",
        "                      # (counting from 0) \n",
        "                      # in the processed_text\n",
        "                        \n",
        "                      if [index_of_i,index_of_j] not in covered_coocurrences:\n",
        "                          weighted_edge[i][j]+=1/math.fabs(index_of_i-index_of_j)\n",
        "                          covered_coocurrences.append([index_of_i,index_of_j])\n",
        "\n",
        "  inout = np.zeros((vocab_len),dtype=np.float32)\n",
        "\n",
        "  for i in range(0,vocab_len):\n",
        "      for j in range(0,vocab_len):\n",
        "          inout[i]+=weighted_edge[i][j]\n",
        "\n",
        "  MAX_ITERATIONS = 50\n",
        "  d=0.85\n",
        "  threshold = 0.0001 #convergence threshold\n",
        "\n",
        "  for iter in range(0,MAX_ITERATIONS):\n",
        "      prev_score = np.copy(score)\n",
        "      \n",
        "      for i in range(0,vocab_len):\n",
        "          \n",
        "          summation = 0\n",
        "          for j in range(0,vocab_len):\n",
        "              if weighted_edge[i][j] != 0:\n",
        "                  summation += (weighted_edge[i][j]/inout[j])*score[j]\n",
        "                  \n",
        "          score[i] = (1-d) + d*(summation)\n",
        "      \n",
        "      if np.sum(np.fabs(prev_score-score)) <= threshold: #convergence condition\n",
        "          #print(\"Converging at iteration \"+str(iter)+\"....\")\n",
        "          break\n",
        "  phrases = []\n",
        "\n",
        "  phrase = \" \"\n",
        "  for word in lemmatized_text:\n",
        "      \n",
        "      if word in stopwords:\n",
        "          if phrase!= \" \":\n",
        "              phrases.append(str(phrase).strip().split())\n",
        "          phrase = \" \"\n",
        "      elif word not in stopwords:\n",
        "          phrase+=str(word)\n",
        "          phrase+=\" \"\n",
        "\n",
        "  unique_phrases = []\n",
        "  for phrase in phrases:\n",
        "      if phrase not in unique_phrases:\n",
        "          unique_phrases.append(phrase)\n",
        "\n",
        "  for word in vocabulary:\n",
        "      #print word\n",
        "      for phrase in unique_phrases:\n",
        "          if (word in phrase) and ([word] in unique_phrases) and (len(phrase)>1):\n",
        "              unique_phrases.remove([word])\n",
        "\n",
        "  phrase_scores = []\n",
        "  keywords = []\n",
        "  for phrase in unique_phrases:\n",
        "      phrase_score=0\n",
        "      keyword = ''\n",
        "      for word in phrase:\n",
        "          keyword += str(word)\n",
        "          keyword += \" \"\n",
        "          phrase_score+=score[vocabulary.index(word)]\n",
        "      phrase_scores.append(phrase_score)\n",
        "      keywords.append(keyword.strip())\n",
        "\n",
        "  res = {keywords[i]: phrase_scores[i] for i in range(len(keywords))}\n",
        "  sorted_index = np.flip(np.argsort(phrase_scores),0)\n",
        "  keywords_num = len(keywords)\n",
        "  final_keywords = []\n",
        "  for i in range(0,keywords_num):\n",
        "    final_keywords.append(str(keywords[sorted_index[i]]))\n",
        "  return final_keywords\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BM3ZE1pvTUz"
      },
      "source": [
        "### KP 20K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBRriFBPue5c",
        "outputId": "c63eaf8f-2b46-4383-9b25-2984d422e092"
      },
      "source": [
        "%%time\n",
        "test_data['textrank'] = test_data['abstract'].apply(lambda x: \",\".join(TextScoring(x)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 13min 30s, sys: 2.66 s, total: 1h 13min 32s\n",
            "Wall time: 1h 13min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL2vozKRm0RZ",
        "outputId": "c89d5270-a6c5-4984-987e-c3cf53ad0da9"
      },
      "source": [
        "evaluate(test_data['textrank'],test_data['keyword'],test_data)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########################\n",
            "Metrics\n",
            "@1\n",
            "F1:0.08421447574685026\n",
            "P:0.92385\n",
            "R:0.04416103114938584\n",
            "@3\n",
            "F1:0.23246069839880634\n",
            "P:0.92825\n",
            "R:0.13320699235767636\n",
            "@5\n",
            "F1:0.35913329645072317\n",
            "P:0.9332400000000002\n",
            "R:0.2231943669216439\n",
            "@10\n",
            "F1:0.6027119712350422\n",
            "P:0.9355400000000001\n",
            "R:0.44726481451268174\n",
            "@30\n",
            "F1:0.8050724486213954\n",
            "P:0.6888683333333333\n",
            "R:0.9785478703172245\n",
            "#########################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAeS2GJ2v-J2"
      },
      "source": [
        "### Inspec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xpEpXsr0m0Ob",
        "outputId": "5dc7dac2-e10e-4056-dc3f-821c6ecea249"
      },
      "source": [
        "inspec_data"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>keyword</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wavelet-based level-of-detail representation o...</td>\n",
              "      <td>3d object level of detail modeling system,wave...</td>\n",
              "      <td>wavelet transform,range images,initial mesh,wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural networks in optimal filtration\\nThe com...</td>\n",
              "      <td>optimal filtering,neural networks,linear filte...</td>\n",
              "      <td>neural networks,white noise,telegraph signal,s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A new high resolution color flow system using ...</td>\n",
              "      <td>high resolution colour flow system,eigendecomp...</td>\n",
              "      <td>color flow,tissue motion,clutter rejection,vel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>New hub gears up for algorithmic exchange\\nWar...</td>\n",
              "      <td>warwick university centre for scientific compu...</td>\n",
              "      <td>warwick university,uk exercise,typical 1960s,s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geometric source separation: merging convoluti...</td>\n",
              "      <td>geometric source separation,geometric beamform...</td>\n",
              "      <td>source separation,undesired interferences,sour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Academic libraries and community: making the c...</td>\n",
              "      <td>academic libraries,community partnerships,camp...</td>\n",
              "      <td>academic libraries,broader community,various u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>CRONE control: principles and extension to tim...</td>\n",
              "      <td>crone control,time-variant plants,asymptotical...</td>\n",
              "      <td>variant plants,crone control,constant coeffici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Mining the optimal class association rule set\\...</td>\n",
              "      <td>optimal class association rule set mining,mini...</td>\n",
              "      <td>class association,association rule,optimal rul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Dynamic testing of inflatable structures using...</td>\n",
              "      <td>thin-film torus,smart materials,satellite appl...</td>\n",
              "      <td>smart materials,vibration testing,inflated str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>Structural interpretation of matched pole-zero...</td>\n",
              "      <td>structural interpretation,matched pole-zero di...</td>\n",
              "      <td>discrete time,transfer function,time systems,t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...                                              tfidf\n",
              "0     Wavelet-based level-of-detail representation o...  ...  wavelet transform,range images,initial mesh,wa...\n",
              "1     Neural networks in optimal filtration\\nThe com...  ...  neural networks,white noise,telegraph signal,s...\n",
              "2     A new high resolution color flow system using ...  ...  color flow,tissue motion,clutter rejection,vel...\n",
              "3     New hub gears up for algorithmic exchange\\nWar...  ...  warwick university,uk exercise,typical 1960s,s...\n",
              "4     Geometric source separation: merging convoluti...  ...  source separation,undesired interferences,sour...\n",
              "...                                                 ...  ...                                                ...\n",
              "1995  Academic libraries and community: making the c...  ...  academic libraries,broader community,various u...\n",
              "1996  CRONE control: principles and extension to tim...  ...  variant plants,crone control,constant coeffici...\n",
              "1997  Mining the optimal class association rule set\\...  ...  class association,association rule,optimal rul...\n",
              "1998  Dynamic testing of inflatable structures using...  ...  smart materials,vibration testing,inflated str...\n",
              "1999  Structural interpretation of matched pole-zero...  ...  discrete time,transfer function,time systems,t...\n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jccC3Y7Sv_zG",
        "outputId": "d7c95316-a2c1-4da1-dbf2-92b8655ae2e7"
      },
      "source": [
        "%%time\n",
        "inspec_data['textrank'] = inspec_data['text'].apply(lambda x: \",\".join(TextScoring(x)))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 9s, sys: 198 ms, total: 5min 9s\n",
            "Wall time: 5min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C35HsN3yv_wO",
        "outputId": "2a1da6ec-f3fd-4935-df13-27430b4b52e6"
      },
      "source": [
        "evaluate(inspec_data['textrank'],inspec_data['keyword'],inspec_data)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########################\n",
            "Metrics\n",
            "@1\n",
            "F1:0.07825176393917326\n",
            "P:0.9865\n",
            "R:0.040762354515670014\n",
            "@3\n",
            "F1:0.21655609182621555\n",
            "P:0.9828333333333333\n",
            "R:0.12185486437709807\n",
            "@5\n",
            "F1:0.33662442617902716\n",
            "P:0.9846\n",
            "R:0.20345775298480362\n",
            "@10\n",
            "F1:0.5754224742236236\n",
            "P:0.9863999999999999\n",
            "R:0.407680187668283\n",
            "@30\n",
            "F1:0.8688829420518646\n",
            "P:0.7905166666666668\n",
            "R:0.9707538140824862\n",
            "#########################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kar08Uxiv_to"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}